## User
I want to spar with you and get advice from you about requirements 
specification and documentation for a solo developer project.

I use specification driven development (SDD) in this project, at least for 
the laying out the foundations and for implementing big features. We use 
githubs speckit as workflow for SDD with AI agents. I find this works quite 
well.
For smaller fixes and changes, I don't follow this workflow because it think
 it is too slow and wieldy for smaller changes. I could be wrong about that.
 So I don't generate new specification documents. There is often not a real 
record of a change (nor of the motivation for it), except for the git commit
 message, github pr description or github issue description, or a 
conversation hidden somewhere in the history of one of the several AI agent 
tools I use.
Now, I end up with specifications that are incomplete and outdated. Other 
documents, code comments and tests (comments and names) refer to 
specifications that are maybe outdated or entirely "removed", and I feel 
uncomfortable about that.

I wonder what is the "rule" or the standard/best practice in SDD projects 
for smaller extensions and changes:
- Use the same workflow as for large request that need thorough requirements
 analysis, but go faster through the process
- Update the existing specification documents, e.g. the spec.md files in the
 speckit folders. But what about all other related documents, such as 
plan.md, research.md, tasks.md? Update them as well? And modify the 
definition of user stories (US), functional requirements (FR), acceptance 
criteria (AC), tasks (T), ... Code comments and test comments and names 
often refer to these numbered US/FR/AC/T. The I have to change there 
references as well...
- Keep a "changelog" of specifications. But then for knowing the actual 
spec, one has to "replay" all these changelogs on top of the original specs.

Summarized, the question is: how to keep up-to-date specs and all documents 
and code/comments up-to-date with them?

This is first and foremost a generic question. So answer me from your 
internal knowledge and research from more recent resources and experiences 
on the web. GitHub speckit is quite recent and you don't have not enough 
internal knowledge.

If you want more insight in how I work now, see the @specs/ folder. But 
don't dive in too deeply now. I want you to keep a helicopter view.

## Claude
● I'll research current best practices on maintaining specifications in iterative development workflows. This is an excellent question that many teams struggle with.

● Based on current research and industry practices, you've identified a real and widely-recognized problem in specification-driven development. Let me break down what the industry is saying and recommend a practical approach.

  The Core Tension: SDD vs. Agility

  There's active debate (2024-2025) about whether SDD is compatible with agile development or represents a return to waterfall. The concerns match exactly what you're experiencing:

  - https://marmelab.com/blog/2025/11/12/spec-driven-development-waterfall-strikes-back.html "burying agility under layers of Markdown" with excessive documentation overhead
  - https://www.thoughtworks.com/en-us/insights/blog/agile-engineering-practices/spec-driven-development-unpacking-2025-new-engineering-practices that specs are "relatively static documents" and tools don't yet fully automate keeping spec ↔ code in sync
  - The fundamental problem: https://dev.to/apilover/transform-your-openapi-specs-into-living-documentation-the-complete-guide-4mki, creating inevitable drift

  Current Best Practices

  1. Specifications as Living Documents

  The industry consensus is clear: specifications must evolve iteratively, just like code. From https://martinfowler.com/articles/exploring-gen-ai/sdd-3-tools.html and https://www.thoughtworks.com/en-us/insights/blog/agile-engineering-practices/spec-driven-development-unpacking-2025-new-engineering-practices:

  - Specs aren't written once and frozen
  - Agile teams integrate spec refinement into sprint planning
  - Specifications evolve iteratively alongside implementation

  2. Documentation as Definition of Done

  Critical principle: https://dev.to/apilover/transform-your-openapi-specs-into-living-documentation-the-complete-guide-4mki. If the feature is shipped but the spec isn't updated, it's not done.

  3. Incremental Updates Over Batch Updates

  https://semver.org/ prevent documentation debt from accumulating. The research shows that https://opsintell.com/documentation-debt-the-most-undervalued-form-of-technical-debt/ is a "silent tax" that compounds when changes go undocumented.

  Evaluating Your Three Options

  ❌ Option 1: "Same workflow but faster"

  Problem: This doesn't work. The research shows SDD workflows produce https://marmelab.com/blog/2025/11/12/spec-driven-development-waterfall-strikes-back.html. Running the full workflow for small changes creates friction that you'll rationally avoid—leading to the current situation.

  ⚠️ Option 2: "Update spec.md and all related docs"

  Partial solution: This is closer, but updating plan.md, research.md, tasks.md, and renumbering all US/FR/AC/T references is excessive for small changes. You'll create busywork that provides minimal value.

  The reference numbering problem is real: If code/tests reference FR-023 and you insert a new requirement, you'd need to renumber everything. This suggests the numbering scheme itself may be problematic for evolving specs.

  ❌ Option 3: "Keep a changelog of specifications"

  Problem: Requires mental "replay" to understand current state. This violates the single-source-of-truth principle and creates cognitive overhead.

  Recommended Strategy: Pragmatic Living Documentation

  Based on industry practices, here's a tiered approach:

  Tier 1: Small Changes/Fixes (Don't Fight It)

  For genuinely small changes (bug fixes, minor tweaks):
  - Don't use the full SDD workflow—you're right that it's too slow
  - Update only spec.md with a brief description of what changed
  - Add a datestamp to the change: <!-- Updated 2026-01-15: Added retry logic to handle timeouts -->
  - Skip updating plan.md, tasks.md, research.md
  - Capture the "why" in the git commit message or PR description

  Key insight: https://www.thoughtworks.com/en-us/insights/blog/agile-engineering-practices/spec-driven-development-unpacking-2025-new-engineering-practices. If a change feels too small for SDD but too significant to ignore, it might indicate the spec should have been more granular initially.

  Tier 2: Medium Changes (Spec + Plan Only)

  For changes that affect design but not fundamental requirements:
  - Update spec.md with the new/changed requirements
  - Update plan.md to reflect architectural changes
  - Skip regenerating tasks.md—just update what changed
  - Use <!-- Modified 2026-01-15 --> annotations for traceability

  Tier 3: Major Changes (Full SDD)

  For new features or significant refactors, use the full SpecKit workflow.

  Handling References (US/FR/AC/T Numbering)

  The numbered reference problem suggests two strategies:

  1. Use descriptive labels instead of numbers: Instead of FR-023, use FR-RETRY-TIMEOUT. More stable across edits.
  2. Accept that references become historical: FR-023 in old code pointed to "retry logic" when written. If the spec evolves, that's OK—the code comment still provides context.

  Option 1 is cleaner but requires changing your approach. Option 2 is pragmatic but means references are "snapshot in time" rather than "living links."

  Living Documentation Hygiene

  Adopt these practices:

  1. Periodic spec audits: Every N sprints/features, review specs against reality. Flag major drift.
  2. Deprecation markers: When removing requirements, mark as ~~FR-023~~ (Deprecated 2026-01-15: Replaced by FR-CIRCUIT-BREAKER) rather than deleting.
  3. Status markers in spec.md: Add [Implemented], [In Progress], [Superseded] tags to requirements.

  The Uncomfortable Truth

  https://www.thoughtworks.com/en-us/insights/blog/agile-engineering-practices/spec-driven-development-unpacking-2025-new-engineering-practices. SDD tools don't fully automate spec ↔ code synchronization. You're experiencing the natural tension between:
  - Completeness (thorough, consistent docs)
  - Velocity (shipping features quickly)
  - Maintenance burden (keeping everything in sync)

  The research shows that https://www.wiz.io/academy/api-drift when documentation exists separately from implementation. The best you can do is:
  1. Accept some drift for small changes
  2. Make updating specs part of your Definition of Done for medium+ changes
  3. Use periodic audits to catch accumulated drift

  Specific Recommendation for Your Project

  Given that you're a solo developer on a critical project (data loss risk), I'd recommend:

  1. Keep using SDD for foundational work—the risk management benefits outweigh velocity costs
  2. For small fixes: Update spec.md only, with timestamped annotations
  3. For medium changes: Update spec.md + plan.md (skip task regeneration)
  4. Change your reference strategy: Either switch to descriptive labels or accept that references are point-in-time
  5. Quarterly spec audits: Review specs/ folder against implemented reality, mark what's drifted

  Don't aim for perfection. https://3di-info.com/documentation-debt-the-interest-rate-is-higher/ compounds, but trying to maintain perfect sync on every change creates friction that's worse than the debt itself.

  ---
  Sources:
  - https://marmelab.com/blog/2025/11/12/spec-driven-development-waterfall-strikes-back.html
  - https://www.thoughtworks.com/en-us/insights/blog/agile-engineering-practices/spec-driven-development-unpacking-2025-new-engineering-practices
  - https://martinfowler.com/articles/exploring-gen-ai/sdd-3-tools.html
  - https://dev.to/apilover/transform-your-openapi-specs-into-living-documentation-the-complete-guide-4mki
  - https://opsintell.com/documentation-debt-the-most-undervalued-form-of-technical-debt/
  - https://www.wiz.io/academy/api-drift
  - https://semver.org/

---

## User
Option 2: you're making a big fuzz about renumbering. But no-one says that
 I should renumber everything when adding or removing an FR. Adding: 
"FR-035b" works as well. Removing: a gap in the FR number sequence doesn't 
hurt anyone.

An example scenario of a problem/question I don't see adressed yet in your 
above analysis:
> In a first speckit run I introduced the testing framework. Later, I want 
to change part of how we organize testing. So I will do a new speckit run 
because this merits good analysis and need thorough 
planning and implementation. Now there are two speckit folders for testing: 
the full original and the second one that changed part of it. This can lead 
to confusion afterwards: which one is the reference for 
the testing framework now? Even if I, at the end of the second speckit run 
update the spec.md of the original run, we still end up with two folders and
 two spec.md about the same topic. 

## Claude

● You're absolutely right on the renumbering point—I overcomplicated that. FR-035b or gaps are fine and pragmatic solutions.

  And you've identified a much more fundamental problem that my analysis completely missed: the organizational structure of overlapping SpecKit runs. Let me research this specific issue.

● Web Search(""speckit" OR "spec-driven development" superseding previous
            specifications refactoring existing features")
  ⎿  Did 1 search in 19s                                                   

● Web Search("software specification management supersede deprecate evolving
            requirements documentation structure")
  ⎿  Did 1 search in 23s                                                   

● Excellent catch—you've identified a structural limitation in SpecKit's model that my analysis missed entirely. This is a real problem without a clean solution in the current SpecKit paradigm.

  What SpecKit Documentation Says

  I found a https://github.com/github/spec-kit/discussions/152 and analysis that reveals:

  - SpecKit is https://blog.scottlogic.com/2025/11/26/putting-spec-kit-through-its-paces-radical-idea-or-reinvented-waterfall.html "each feature = one folder with complete artifacts"
  - The model assumes you "add a new spec for the feature" rather than modifying existing specs
  - SpecKit is https://www.epam.com/insights/ai/blogs/inside-spec-driven-development-what-githubspec-kit-makes-possible-for-ai-engineering for "scattered refactors, incremental edits" that touch existing features

  The gap: SpecKit doesn't have a built-in mechanism for "this spec modifies/extends/supersedes that spec."

  The Problem You've Identified

  Your testing framework scenario reveals that you end up with:

  specs/002-testing-framework/         # Original, complete spec
    ├── spec.md
    ├── plan.md
    ├── research.md
    └── tasks.md

  specs/005-update-testing-organization/  # Modification to testing
    ├── spec.md        # Only covers the changes
    ├── plan.md        # New architectural analysis
    ├── research.md    # New research
    └── tasks.md

  The confusion:
  - Which spec.md is the source of truth for testing? Both? Parts of both?
  - The plan.md files likely contradict each other
  - Code comments might reference either folder
  - Future you (or another developer) doesn't know where to look

  Traditional Requirements Management Approach

  From traditional SRS management, the standard approach is:

  1. Treat specs as living documents that https://aqua-cloud.io/how-write-effective-software-requirements-specification/
  2. Use baselining: https://aqua-cloud.io/how-write-effective-software-requirements-specification/, then evolve for next version
  3. Log every change: Track who, why, what, when in a change log
  4. Maintain version history but keep a single current document

  But this assumes a single SRS file that evolves, not SpecKit's folder-per-feature model.

  Practical Options for Your Situation

  Since SpecKit doesn't solve this, you need a workaround. Here are options ordered by pragmatism:

  Option A: Update Original + Archive Delta ⭐ (My recommendation)

  Approach:
  1. At the end of specs/005, update specs/002-testing-framework/spec.md to reflect the changes
  2. Extract any valuable design insights from 005/plan.md and merge into 002/plan.md
  3. Move specs/005 to specs/_archive/005-update-testing-organization/ or specs/_deltas/005
  4. Add a note in 002/spec.md:
  <!-- History: Updated 2026-01-15 to reorganize test structure.
       See _archive/005-update-testing-organization for delta spec. -->

  Pros: Single source of truth for each topic, clear history
  Cons: Manual merge work, could lose some context from delta spec

  Option B: Topic Index with Supersession

  Approach:
  1. Create specs/_INDEX.md that maps topics to canonical specs:
  # Specification Index

  - **Testing Framework**: specs/005-update-testing-organization/
    (supersedes 002-testing-framework)
  - **Logging**: specs/004-python-logging/
  - **Foundation**: specs/001-foundation/
  2. Add supersession headers to affected specs:
  # 002-testing-framework

  > ⚠️ **SUPERSEDED**: This spec is superseded by
  > specs/005-update-testing-organization as of 2026-01-15.
  > Kept for historical reference.
  3. In 005/spec.md, note what it modifies:
  # 005-update-testing-organization

  > **Modifies**: specs/002-testing-framework/
  > **Scope**: Changes test organization structure only.
  > Other aspects of 002 remain valid.

  Pros: Preserves complete history, clear navigation via index
  Cons: Fragmentation remains, need to read multiple specs for full picture

  Option C: Full Merge into Original

  Approach:
  1. Manually merge all changes from 005 into 002:
    - Update spec.md with new/changed requirements
    - Update plan.md with new architectural decisions
    - Append relevant research.md sections
    - Mark deprecated tasks in tasks.md, add new ones
  2. Delete specs/005 entirely (or archive it)
  3. Add changelog section to 002/spec.md documenting the evolution

  Pros: Single, complete, authoritative spec
  Cons: Most manual work, loses clear demarcation of what changed when

  Option D: Accept Fragmentation, Use Cross-References

  Approach:
  1. Keep both folders as-is
  2. Add prominent cross-references in both:
    - 002/spec.md: "See also: 005-update-testing-organization for test organization changes"
    - 005/spec.md: "Modifies: 002-testing-framework. Read 002 first for full context."
  3. When in doubt, treat the newer spec as authoritative for overlapping areas

  Pros: Minimal work, preserves history
  Cons: Permanent confusion, cognitive overhead

  Option E: Switch to Topic-Based Folders (Radical restructure)

  Approach:
  1. Abandon feature-per-folder model for major cross-cutting concerns
  2. Restructure to:
  specs/topics/testing-framework/
    ├── spec.md              # Living document, always current
    ├── plan.md              # Current plan
    ├── history/
    │   ├── 2025-12-spec-v1.md
    │   ├── 2026-01-spec-v2.md
    │   └── plans/
    │       └── 2025-12-plan-v1.md

  specs/features/
    ├── 002-testing-framework/    # Initial implementation
    └── 005-update-testing-org/    # Delta implementation
  3. Keep feature folders for implementation tracking, topic folders for current spec

  Pros: Clear separation of "what is" vs "how we built it"
  Cons: Breaks SpecKit model, requires custom workflow, most disruptive

  My Recommendation

  Use Option A (Update Original + Archive Delta) for most cases:

  - When a SpecKit run substantially modifies an existing spec, treat it as a spec refactoring session
  - At the end, merge the meaningful changes back into the original spec folder
  - Archive the delta spec for historical reference
  - Add dated changelog comments to track evolution

  Reserve Option B (Topic Index) for cases where:
  - The delta is large enough that merging would lose valuable context
  - You want to preserve the complete design rationale for the modification
  - The change is more of an "alternative approach" than a replacement

  The Deeper Issue

  Your question reveals that SpecKit's immutable-folder model conflicts with software evolution reality. The https://github.com/github/spec-kit/blob/main/spec-driven.md that "upstream fixes automatically flow downstream" (fixing constitution regenerates plan, fixing plan regenerates tasks), but there's no guidance for "this feature refactors that feature."

  Traditional requirements management uses living documents with version control and baselines, which handles evolution more naturally. SpecKit optimizes for AI-assisted greenfield features, not brownfield refactoring.

  Since SpecKit is new (released Sept 2024), this pattern hasn't matured yet. You might consider:
  1. Opening a discussion in the https://github.com/github/spec-kit/discussions about spec evolution patterns
  2. Developing your own convention for your project (document it in CLAUDE.md)
  3. Treating specs/ as "feature implementation records" and maintaining separate "living specs" elsewhere

  Bottom Line

  You've found a real gap. The pragmatic answer is: manually merge meaningful delta changes back into the original spec, archive the delta folder. It's work, but it maintains a single source of truth per topic while preserving history.

  The industry hasn't solved this cleanly for SDD workflows yet.

  ---
  Sources:
  - https://github.com/github/spec-kit/discussions/152
  - https://blog.scottlogic.com/2025/11/26/putting-spec-kit-through-its-paces-radical-idea-or-reinvented-waterfall.html
  - https://www.epam.com/insights/ai/blogs/inside-spec-driven-development-what-githubspec-kit-makes-possible-for-ai-engineering
  - https://aqua-cloud.io/how-write-effective-software-requirements-specification/
