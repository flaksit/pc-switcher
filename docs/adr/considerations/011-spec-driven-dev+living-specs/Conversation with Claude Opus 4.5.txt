## User
I want to spar with you and get advice from you about requirements 
specification and documentation for a solo developer project.

I use specification driven development (SDD) in this project, at least for 
the laying out the foundations and for implementing big features. We use 
githubs speckit as workflow for SDD with AI agents. I find this works quite 
well.
For smaller fixes and changes, I don't follow this workflow because it think
 it is too slow and wieldy for smaller changes. I could be wrong about that.
 So I don't generate new specification documents. There is often not a real 
record of a change (nor of the motivation for it), except for the git commit
 message, github pr description or github issue description, or a 
conversation hidden somewhere in the history of one of the several AI agent 
tools I use.
Now, I end up with specifications that are incomplete and outdated. Other 
documents, code comments and tests (comments and names) refer to 
specifications that are maybe outdated or entirely "removed", and I feel 
uncomfortable about that.

I wonder what is the "rule" or the standard/best practice in SDD projects 
for smaller extensions and changes:
- Use the same workflow as for large request that need thorough requirements
 analysis, but go faster through the process
- Update the existing specification documents, e.g. the spec.md files in the
 speckit folders. But what about all other related documents, such as 
plan.md, research.md, tasks.md? Update them as well? And modify the 
definition of user stories (US), functional requirements (FR), acceptance 
criteria (AC), tasks (T), ... Code comments and test comments and names 
often refer to these numbered US/FR/AC/T. The I have to change there 
references as well...
- Keep a "changelog" of specifications. But then for knowing the actual 
spec, one has to "replay" all these changelogs on top of the original specs.

Summarized, the question is: how to keep up-to-date specs and all documents 
and code/comments up-to-date with them?

This is first and foremost a generic question. So answer me from your 
internal knowledge and research from more recent resources and experiences 
on the web. GitHub speckit is quite recent and you don't have not enough 
internal knowledge.

If you want more insight in how I work now, see the @specs/ folder. But 
don't dive in too deeply now. I want you to keep a helicopter view.

## Claude

● This is a great question that touches on a real tension in specification-driven development. Let me first search for recent thinking on this, then give you my synthesis.

● Now I have a clear picture of your situation. You have FR-XXX references embedded in code comments, creating tight coupling between code and specs. Let me give you my synthesis.

  The Core Problem

  You've identified a real tension that the SDD community is actively grappling with. The https://www.thoughtworks.com/en-us/insights/blog/agile-engineering-practices/spec-driven-development-unpacking-2025-new-engineering-practices explicitly calls out "specs that drift" and "poor change management" as key risks of SDD.

  The fundamental issue isn't the specs themselves—it's the coupling you've created between code and spec identifiers (FR-010, US-02, etc.). Every reference creates a maintenance burden.

  Three Approaches (with my assessment)

  1. Tiered Documentation (Recommended)

  Not all changes need the same treatment. A practical split:

  | Change Type       | Documentation Approach                                |
  |-------------------|-------------------------------------------------------|
  | New major feature | Full SDD workflow (spec → plan → tasks)               |
  | Feature extension | Update existing spec.md, skip plan/tasks regeneration |
  | Bug fix           | Git commit message + issue description only           |
  | Refactoring       | Git commit message only                               |

  The https://agilemodeling.com/essays/agiledocumentation.htm calls this "document stable things, not speculative ideas" and "update only when it hurts."

  2. Decouple Code from Spec Identifiers

  This is the bigger insight. Your current pattern:
  # Per FR-010, verifies both hosts have sufficient disk space

  This creates mechanical coupling that breaks when specs evolve. Alternatives:

  Option A: Reference spec files, not IDs
  # See specs/001-foundation/spec.md - disk space verification

  Option B: Describe intent, not spec reference
  # Verify sufficient disk space on both hosts before sync

  Option C: Use tests as executable specifications
  The https://agilemodeling.com/essays/agiledocumentationbestpractices.htm suggest: most specification content can be captured as "executable specifications" in tests. Your test names and assertions are the spec—they're always in sync because they run.

  3. Accept Controlled Staleness

  This is counterintuitive but practical: not everything needs to be current.

  For a solo project, distinguish:
  - Living documents: spec.md (the "what"), your README, ADRs
  - Point-in-time artifacts: plan.md, tasks.md, research.md (how you got there)

  The plan/tasks/research are historical records of your decision process. They don't need updating—they explain why the spec is what it is. Let them be.

  Practical Recommendations for Your Project

  1. Stop adding FR-XXX references to new code. Use descriptive comments or reference spec files instead. The existing references can stay—they're not actively harmful, just less maintainable.
  2. For small changes: Update spec.md inline if the change affects requirements. Skip updating plan.md/tasks.md/research.md—treat them as historical artifacts.
  3. For spec updates: Add a ## Changelog section at the bottom of spec.md rather than maintaining a separate changelog file. This keeps the current state readable without needing to "replay" anything.
  4. Consider "spec-anchored" vs "spec-first": The https://martinfowler.com/articles/exploring-gen-ai/sdd-3-tools.html distinguishes these. You seem to want spec-anchored (specs maintained over time), not spec-as-source (specs are the only truth). That's fine—just be explicit about it.
  5. Ruthlessly delete review documents after incorporation. Your spec has 7+ review files. Once feedback is resolved and incorporated, these are noise. Either archive them or delete them.

  My Take

  The SDD community hasn't solved this problem yet—it's too new. The https://blog.scottlogic.com/2025/12/15/the-specification-renaissance-skills-and-mindset-for-spec-driven-development.html notes we're in a "specification renaissance" still figuring out best practices.

  For a solo developer, I'd optimize for:
  1. Specs that are "good enough" not perfect — you'll be the one reading them
  2. Minimal coupling — don't create cross-references you'll have to maintain
  3. Tests as the living spec — if it matters, it should be tested

  The discomfort you feel about outdated specs is valid—but the solution isn't "update everything always." It's "be deliberate about what needs to stay current and decouple the rest."

  ---
  Would you like to discuss any of these approaches in more depth, or explore how to restructure your current specs/ folder to reduce maintenance burden?

---

## User
Aren't your 3 proposed approaches not complementary rather than distinct?

About approach 2. Why decouple? I often see that, when implementing a change
 towards a previously defined functional requirement, the AI agent forgets 
to update some of the code and certainly tests that contain comment/naming 
references to the functional requirement. When we decide to change a 
previous spec, it is easy to find the code and tests that implement it, to 
be sure we refactor ALL impacted code.
Option C is quite contested. And I don't like it :-p

Practical recommendation:
3. This internal changelog is still a changelog and still needs "replaying 
in the mind": read the doc with the old spec, then read one change after the
 other, to finally reconstruct a mental image of the full current spec.
4. I rather want spec-as-source I think. But this doesn't mean that I never 
can touch code myself, does it?

You only gave some some pointers and ideas, but they don't solve the 
challenges I face.
Example of one of my questions:
> In a first speckit run I introduced the testing framework. Later, I want 
to change part of how we organize testing. So I will do a new speckit run 
because this merits good analysis and need thorough planning and 
implementation. Now there are two speckit folders for testing: the full 
original and the second one that changed part of it. This can lead to 
confusion afterwards: which one is the reference for the testing framework 
now? Even if I, at the end of the second speckit run update the spec.md of 
the original run, we still end up with two folders and two spec.md about the
 same topic.

What would you recommend for my main concern: having somewhere a current 
view on the specs? I need a concrete workflow to have current spec-alike 
docs somehow.

## Claude

● You're right on both counts. Let me be more concrete.

  On the Coupling Question

  You make a valid case. The FR-XXX references are intentional coupling that provides:
  - Traceability from code back to requirements
  - Easy grep to find all implementations when a requirement changes
  - Forcing function for AI agents to update all related code

  The issue isn't the coupling itself—it's what happens when specs evolve. Two approaches to keep the coupling useful:

  Immutable IDs: Once FR-010 exists, it never gets renumbered. If you fundamentally change it, deprecate and create FR-045. The spec shows "FR-010 (superseded by FR-045)". This is how APIs handle breaking changes.

  Stable IDs: FR-010 means "disk space verification"—the concept is stable even if details evolve. The ID is a category, not a version.

  Your Core Problem: Multiple Folders, One Domain

  Let me directly address your testing example:

  specs/002-testing-framework/   ← original
  specs/00X-testing-reorg/       ← changes part of it

  You now have two references for "testing." Which is truth?

  Proposed Workflow: Consolidate After Implementation

  ┌─────────────────────────────────────────────────────────────┐
  │  SPECKIT RUN (generates new folder)                         │
  │  specs/00X-testing-reorg/                                   │
  │    spec.md, plan.md, tasks.md, ...                          │
  └─────────────────────────────────────────────────────────────┘
                            │
                            ▼
  ┌─────────────────────────────────────────────────────────────┐
  │  IMPLEMENT                                                  │
  │  Use speckit.implement, code changes land                   │
  └─────────────────────────────────────────────────────────────┘
                            │
                            ▼
  ┌─────────────────────────────────────────────────────────────┐
  │  CONSOLIDATE (new step)                                     │
  │  1. Update specs/002-testing-framework/spec.md with changes │
  │  2. Move 00X/ to specs/_history/00X-testing-reorg/          │
  │     (or delete if you don't need the decision history)      │
  └─────────────────────────────────────────────────────────────┘

  Result: specs/002-testing-framework/spec.md remains THE source of truth for testing. The incremental folder becomes historical record or is deleted.

  Concrete Rules

  1. One folder per domain, not per change
    - 001-foundation = foundation domain
    - 002-testing-framework = testing domain
    - New changes TO testing update 002-testing-framework/spec.md
  2. Speckit folders are workflow artifacts, not permanent structure
    - Use speckit to do the analysis/planning/implementation
    - After implementation, consolidate changes back to the domain folder
    - Archive or delete the incremental folder
  3. The spec.md in each domain folder is the living spec
    - It gets updated after each speckit run that touches that domain
    - FR-XXX references in code point here
    - This is your "current view on specs"
  4. plan.md, tasks.md, research.md are historical
    - They explain HOW you got to the current spec
    - They don't need updating—they're snapshots of decision-making
    - Keep them in the domain folder or archive them

  What About spec-as-source?

  You can still touch code directly. "Spec-as-source" means the spec is the authoritative definition of intent—not that code is generated-only. When you touch code for a small fix:
  - If it changes behavior defined in a spec → update the spec.md
  - If it's implementation detail not in spec → no spec update needed

  Directory Structure After This Workflow

  specs/
  ├── 001-foundation/
  │   ├── spec.md          ← LIVING: current foundation spec
  │   ├── plan.md          ← historical
  │   ├── tasks.md         ← historical
  │   └── research.md      ← historical
  ├── 002-testing-framework/
  │   ├── spec.md          ← LIVING: current testing spec (updated after 00X)
  │   ├── plan.md          ← historical (from original run)
  │   └── ...
  ├── _history/            ← optional: archived incremental runs
  │   └── 00X-testing-reorg/
  │       ├── spec.md      ← what changed
  │       ├── plan.md      ← how we planned it
  │       └── ...

  The Consolidation Step

  This is the key new practice. After implementing changes from a speckit run:

  # Pseudocode for the consolidation step
  1. Read the new spec.md (what changed)
  2. Update the original domain's spec.md:
     - Modify changed FRs in place
     - Add new FRs with new numbers (continuing sequence)
     - Mark deprecated FRs as "(deprecated, see FR-XXX)"
  3. Optionally add a changelog entry at bottom of spec.md:
     ## Changelog
     - 2025-01-01: FR-015 added, FR-008 updated (see specs/_history/00X-testing-reorg/)
  4. Move incremental folder to _history/ or delete

  ---
  Does this address your concern? The "current view" is always the spec.md in the domain folder. The consolidation step is new work, but it's bounded and mechanical.

  The question is whether you want to do this consolidation manually or whether we should think about tooling/automation for it.
